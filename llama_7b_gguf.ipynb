{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 2576.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching 0 files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " revolutionize healthcare in ways we can't even imagine yet. obviously, there are many challenges and obstacles that need to be overcome but the potential for improvement in patient outcomes, efficiency, and quality of care is huge.\n",
      "– David Drori 1/2 #AIinHealthcare #DigitalHealth\n",
      "Twitter is a great platform to learn about AI and its applications in various industries. By following experts like David Drori, you can stay updated on the latest developments and trends in AI. Here are some other experts you might want to follow:\n",
      "1. @DrJenGunter - Dr. Jen Gunter is a Canadian-based physician and AI expert who writes about the intersection of AI and healthcare. She has a popular Twitter account with insights on how AI can improve patient care, as well as the challenges that need to be addressed.\n",
      "2. @timosteller - Tim O'Reilly is a well-known author and speaker on AI and its applications in various industries. He has written extensively on the potential of AI to transform healthcare, and his Twitter account provides valuable insights into the latest developments in\n"
     ]
    }
   ],
   "source": [
    "### Using Specific Model File (pre-downloaded)\n",
    "\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "# MODEL FILES CAN BE DOWNLOADED FROM https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF\n",
    "# Download Model and Place in HuggingFace Local Cache (run notebook cell to see where model is expected to be placed)\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Llama-2-7b-Chat-GGML\", \n",
    "                                           model_file=\"llama-2-7b-chat.Q4_K_M.gguf\", \n",
    "                                           model_type=\"llama\",\n",
    "                                           gpu_layers=0\n",
    "                                           )\n",
    "\n",
    "print(llm(\"AI is going to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)a5de6028/config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 43.4kB/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Downloading ggml-model.bin: 100%|██████████| 251M/251M [00:11<00:00, 21.2MB/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:12<00:00, 12.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"marella/gpt-2-ggml\", hf=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'AI is going to be a big part of the future of the company.\\n\\n\"We\\'re going to be able to do things that are very different from what we do now,\" he said. \"We\\'re going to be able to do things that are very different from what we do now.\"\\n\\nThe company is also looking to expand its mobile app business, which is expected to grow to $1 billion by 2020.\\n\\n\"We\\'re going to be able to do things that are very different from what we do now,\" he said. \"We\\'re going to be able to do things that are very different from what we do now.\"\\n\\nThe company is also looking to expand its mobile app business, which is expected to grow to $1 billion by 2020.\\n\\nThe company is also looking to expand its mobile app business, which is expected to grow to $1 billion by 2020.\\n\\nThe company is also looking to expand its mobile app business, which is expected to grow to $1 billion by 2020.\\n\\nThe company is also looking to expand its mobile app business, which is expected to grow to $1 billion by 2020.\\n\\nThe company is also looking to expand its mobile app business, which is expected to grow to $1 billion by 2020'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"AI is going to\", max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
